{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdde81c9-704e-458d-b772-5a726e37f76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "import imageio\n",
    "import time\n",
    "import torch\n",
    "from MazeEnvironment import MazeEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14507345-ae9d-42f1-ab86-9923f5702cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_cnn(env, cnn, cmap = 'gray', save_path = None): \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    observations, _ = env.reset()\n",
    "    img = observations['image']/ 255.0 \n",
    "    \n",
    "    plt.imshow(img)\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path + \"_inp.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    x = torch.FloatTensor(img).unsqueeze(0)\n",
    "    x = torch.permute(x, (0, 3, 1, 2)).to(device)\n",
    "    for i, layer in enumerate(cnn):\n",
    "        with torch.no_grad():\n",
    "            x = layer(x)\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            num_channels = x.size()[1]\n",
    "            fig, axs = plt.subplots(int(round(num_channels**0.5)), int(round(num_channels**0.5)))\n",
    "            ax = axs.ravel()\n",
    "            for i in range(num_channels):\n",
    "                ax[i].set_title(f'Channel {i}')\n",
    "                ax[i].imshow(x.cpu().detach().numpy()[0, i], cmap = cmap)\n",
    "                ax[i].axis('off')\n",
    "            if save_path is not None:\n",
    "                plt.savefig(save_path + str(i) + '.png')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c710fcc5-a0d2-4861-8e6e-326591776a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate_policy(env, model, FPS: int = 12, do_truncate: bool = True, goal_dist=None):\n",
    "    figure_size = (5, 5)\n",
    "\n",
    "    s, _ = env.reset(options = {'goal_dist':goal_dist})\n",
    "    \n",
    "    env_info = {\n",
    "        'actions': lambda a: [\"↑\",\"→\",\"←\",\"↓\"][a[0]],\n",
    "        'state_interpreter': lambda s: str(s['telemetry']),\n",
    "    }\n",
    "\n",
    "    step = 0\n",
    "    \n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        action = model.predict(s)\n",
    "        \n",
    "        step += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        plt.figure(figsize=figure_size)\n",
    "        plt.imshow(s['image'])\n",
    "        plt.axis('off')\n",
    "        \n",
    "        interp = env_info['state_interpreter'](s)\n",
    "        action_str = env_info['actions'](action)\n",
    "        \n",
    "        # Add information below the image\n",
    "        plt.text(0.5, -0.15, f\"State: {interp}\\nAction: {action_str}\\nTime Step: {step}\", \n",
    "         transform=plt.gca().transAxes, fontsize=12, \n",
    "         verticalalignment='bottom', horizontalalignment='center')\n",
    "        \n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        s, r, terminated, truncated, _ = env.step(action[0])\n",
    "        r = float(r)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        if FPS:\n",
    "            time.sleep(max(0,1 / FPS - (end_time - start_time)))\n",
    "            \n",
    "        if terminated or (truncated and do_truncate):\n",
    "            break\n",
    "    \n",
    "    # Show final frame\n",
    "    clear_output(wait=True)\n",
    "    img, telemetry = s\n",
    "    frame = img\n",
    "    \n",
    "    plt.figure(figsize=figure_size)\n",
    "    plt.imshow(s['image'])\n",
    "    plt.axis('off')\n",
    "    \n",
    "    interp = env_info['state_interpreter'](s)\n",
    "    \n",
    "    plt.text(0.5, -0.15, f\"Final State: {interp}\\nAction: {action_str}\\nTime Step: {step}\", \n",
    "         transform=plt.gca().transAxes, fontsize=12, \n",
    "         verticalalignment='bottom', horizontalalignment='center')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6cdc82-281a-435c-8d29-3186919191b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate_and_save(env, model, video_path, FPS: int = 12, do_truncate: bool = True, goal_dist=None):\n",
    "    figure_size = (5, 5)\n",
    "    s, _ = env.reset(options={'goal_dist': goal_dist})\n",
    "\n",
    "    env_info = {\n",
    "        'actions': lambda a: [\"↑\", \"→\", \"←\", \"↓\"][a[0]],\n",
    "        'state_interpreter': lambda s: str(s['telemetry']),\n",
    "    }\n",
    "\n",
    "    step = 0\n",
    "    frames = []\n",
    "\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "        action = model.predict(s)\n",
    "        step += 1\n",
    "\n",
    "        # Create the figure\n",
    "        fig, ax = plt.subplots(figsize=figure_size)\n",
    "        ax.imshow(s['image'])\n",
    "        ax.axis('off')\n",
    "\n",
    "        interp = env_info['state_interpreter'](s)\n",
    "        action_str = env_info['actions'](action)\n",
    "\n",
    "        # Text overlay\n",
    "        ax.text(0.5, -0.15, f\"State: {interp}\\nAction: {action_str}\\nTime Step: {step}\",\n",
    "                transform=ax.transAxes, fontsize=12,\n",
    "                verticalalignment='bottom', horizontalalignment='center')\n",
    "\n",
    "        # Convert the matplotlib figure to a NumPy array\n",
    "        canvas = FigureCanvas(fig)\n",
    "        canvas.draw()\n",
    "        frame = np.frombuffer(canvas.tostring_rgb(), dtype='uint8')\n",
    "        frame = frame.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "        frames.append(frame)\n",
    "\n",
    "        plt.close(fig)\n",
    "\n",
    "        s, r, terminated, truncated, _ = env.step(action[0])\n",
    "        if terminated or (truncated and do_truncate):\n",
    "            break\n",
    "\n",
    "        end_time = time.time()\n",
    "        if FPS:\n",
    "            time.sleep(max(0, 1 / FPS - (end_time - start_time)))\n",
    "\n",
    "    # Final frame\n",
    "    fig, ax = plt.subplots(figsize=figure_size)\n",
    "    ax.imshow(s['image'])\n",
    "    ax.axis('off')\n",
    "    interp = env_info['state_interpreter'](s)\n",
    "    ax.text(0.5, -0.15, f\"Final State: {interp}\\nAction: {action_str}\\nTime Step: {step}\",\n",
    "            transform=ax.transAxes, fontsize=12,\n",
    "            verticalalignment='bottom', horizontalalignment='center')\n",
    "\n",
    "    canvas = FigureCanvas(fig)\n",
    "    canvas.draw()\n",
    "    frame = np.frombuffer(canvas.tostring_rgb(), dtype='uint8')\n",
    "    frame = frame.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    frames.append(frame)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Save the frames as a video\n",
    "    print(f\"Saving video to {video_path}...\")\n",
    "    imageio.mimsave(video_path, frames, fps=FPS)\n",
    "    print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a49fec5-6668-4bfc-89f6-13d6651f3eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook plots.ipynb to python\n",
      "[NbConvertApp] Writing 2853 bytes to plots.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to python plots.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e08c3e-4529-4a25-b303-c453d9361962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
